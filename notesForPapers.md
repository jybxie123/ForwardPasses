## Fine-Tuning Language Models with Just Forward Passes

1.Abstract:

This model has 12 times less memory than classic bachpropagation method.

The same memory usage as inference. In fine tune. As a result, the training time is much longer than the basic method.

2.LMs forward gradient pass.


## IS SYNTHETIC DATA FROM GENERATIVE MODELS READY FOR IMAGE RECOGNITION?

three parts:

data for zero-shot image generation

合成数据用于fine tune分类器效果有提升，相比于零样本模型clip。但是如果训练编码器的话就会有下降，如果从头训练某个模型比如resnet50等，也会有下降。

当前从文本到图像生成模型的合成数据确实可以为各种零样本图像分类任务带来显着的性能提升，并且很容易适用于精心设计的策略，例如大规模预训练模型。 当用于零样本任务时，多样性和可靠性对于合成数据很重要。 当使用合成数据从头开始训练模型时，合成数据无法提供令人满意的性能，并且与真实数据相比，数据效率和解决分类任务的效果要低得多。（合成数据集与真实数据分布之间存在域差异）

data for few-shot image generation.

在这个任务下的合成数据特性也是类似的。但是有真实数据的情况下，可以合理利用真实数据以期达到更好的性能。至于如何结合真实数据和合成数据以共同训练，实测中混合会比二阶段训练达到更好的效果。

且使用真实数据来指导合成数据是比使用真实数据筛选合成数据更好的手段。

实际情况中，合成数据有效提高了小样本图像识别的分类器性能，但是随着真实数据的增加，合成数据的提升效能逐渐变低。实际上，合成数据总是要比真实数据差一点，因为合成数据会有域差距和噪声，而真实数据则会有少样本时不稳定的问题。随着更多真实数据的出现，合成数据的积极影响将会减弱，这进一步证实了我们之前的观点，即在训练分类模型中合成数据仍然不如真实数据有效。

synthetic data for pre-training.

数据的重要特性：数据量、多样性。

合成数据的两种情景：

1.下游感知，知道下游标签

对于下游可知的情况，采用合成数据2.4m以上可以超过仅用in-1k预训练的效果。且两者兼具的话效果更好。

2.下游不可知，不知道下游标签，通过通用的多样化标签空间来生成。如imagenet-1K，然后再在cifar-100上生成。

随着数据量和多样性的增加，效果越来越好，最终接近持平in-1k上的moco-v2对应版本。

使用vit效果更好，可知该模型具有对大规模数据学习的更强能力。

合成数据预训练的几项结论：

1. 数据量对综合预训练有积极影响；可以通过增加合成数据大小来提高性能，但随着数据量的增加，性能会逐渐饱和。
2. 预训练的合成数据与预训练的真实数据正交。
3. 对于下游感知的合成预训练，我们在 CIFAR-100 上使用 2.4M/3.6M 合成数据，显着优于 IN-1K Real (1.2M) 预训练。
4. 对于下游不可知的综合预训练，我们取得了与 ImageNet (IN-1k) Real 预训练相当的结果；自监督预训练比监督预训练表现更好，基于 ViT 的主干比基于卷积的主干表现更好。此外，增加标签空间大小可以进一步提高性能。


## Synthetic Data from Diffusion Models Improves ImageNet Classification

简述：生成合成数据有利于在image net上实现多个框架超过基线的分类性能。

我们展示了 Imagen 文本到图像模型，当在 ImageNet 训练集上进行微调时，根据其 Fréchet 起始距离 (FID)，可以在多个分辨率下生成最先进的类条件 ImageNet 模型（Heusel 等人） al., 2017) 和 Inception Score (IS) (Salimans et al., 2016)； 例如，我们在 256 × 256 图像样本上获得的 FID 为 1.76，IS 为 239。 无论是否使用改进模型采样的指导，这些模型都优于现有的最先进模型。 我们进一步确定，来自此类微调的类条件模型的数据还提供了新的最先进的分类准确度分数 (CAS)（Ravuri & Vinyals，2019），通过在合成图像上训练 ResNet-50 模型来计算，然后 在真实的 ImageNet 验证集上评估它们（图 1 - 右）。 最后，我们表明，通过将合成数据与真实数据、大量合成数据以及更长的训练时间相结合，在生成数据上训练的模型的性能进一步提高。 这些结果适用于许多基于卷积和 Transformer 的架构（图 1 - 左）


评估标准：

Inception Score (Salimans et al., 2016) 来评估生成模型的视觉质量是标准做法。由于计算成本相对较低，这些指标被广泛用作生成模型训练和调整的代理。然而，这两种方法都倾向于严厉惩罚非 GAN 模型，并且 Inception Score 在经过采样修改的方法中产生过于乐观的分数（Ho & Salimans，2022；Ravuri & Vinyals，2019）。 Ravuri & Vinyals (2019) 还认为，这些指标与评估分类准确性等下游任务性能的指标并没有表现出一致的相关性。

另一个：lassification accuracy score (CAS),


实验：生成模型训练及采样

我们将解决两个主要问题：大规模文本到图像模型是否可以作为类条件 ImageNet 模型进行微调，以及这些模型在多大程度上可用于生成数据增强。

例如，如果人们天真地使用短文本描述符，例如 Radford 等人为 CLIP 制作的描述符。 (2021) 作为每个 ImageNet 类的文本提示，Imagen 模型生成的数据 (Saharia et al., 2022b) 很容易证明会产生较差的 ImageNet 分类器。一个问题是文本标签可能与多种视觉概念相关，或者与 ImageNet 系统不同的视觉概念相关（见图 2）。这种糟糕的性能也可能是 Imagen 使用高指导权重的结果，从而牺牲了样本质量的生成多样性。虽然有多种方法可以将文本到图像模型重新用作类条件模型，例如，优化提示以最小化分布变化，但这里我们将提示修复为关联的 CLIP 类名称（Radford 等人） al., 2021），并对基于扩散的生成模型的权重和采样参数进行微调


方法一：对生成模型参数进行微调，以期更好的生成优质合成数据。

方法二：对采样参数进行超参的选取。对64和646->256的上采样模型进行超参的选取。

result：

正如人们所预料的那样，仅根据生成的样本训练的模型比根据真实数据训练的模型表现更差。尽管如此，使用扩散模型中的合成图像来增强真实数据可以显着提高所有测试分类器的性能；使用配对 t 检验，结果具有统计显着性，p = 10−5。此外，ConvNets 相对于 Transformer 的性能提升没有明显趋势，因为性能增益随多个因素而变化，包括模型参数的数量和输入图像的分辨率

合成数据在多样性和数据量上增长后对性能有提升作用。

接下来我们考虑 ResNet-50 分类器的性能如何取决于用于增强真实数据的生成数据量。 在这里，我们遵循传统的训练方法，使用随机裁剪进行 130 个时期的训练，与表 2 中使用中心裁剪和仅 90 个时期的 CAS 结果相比，这里产生的 ResNet-50 准确度更高。 附录提供了培训详细信息。
Ravuri & Vinyals (2019)（他们的图 5）发现，对于几乎所有测试的模型，将生成的样本与真实数据混合会降低 Top-5 分类器的准确性。 对于具有低截断值（牺牲样本质量多样性）的 Big-GAN-deep（Brock 等人，2019），生成的数据量较少时，准确率略有增加，但随后很快下降到仅在真实数据上训练的模型以下： 生成的数据量接近真实训练集的大小。 相比之下，图 6 显示，对于 64×64 图像，随着生成的数据量增加至实际数据量的九倍，达到 12M 图像的总数据集大小，性能持续提高。 来自两个更高分辨率模型的样本的性能随着多达 1.2M 合成样本的增加而增加，然后缓慢下降。 尽管如此，性能仍然高于仅在真实数据上训练最多约 4M 合成样本的基线模型，即合成数据比真实数据多三倍。 （附录中的表 A.3 以表格形式提供了这些结果。）

但是这种生成图像的效果对于其他图像领域功效暂且不知。

其他：

最后，我们的实验发现了一些值得进一步研究的意想不到的现象。其中之一是 CAS 在 1024 × 1024 分辨率下的提升，这表明较大的图像比 256 × 256 的图像捕获更有用的图像结构，即使 1024 × 1024 图像在中心裁剪到 224 × 之前被下采样到 256 × 256 224 用于 ResNet-50 的输入。另一个问题涉及 64×64 的大量合成数据的分类准确性的持续增益，而在更高分辨率下，增益不是单调的（图 6 和表 A.3）。低分辨率下用于训练的信息可能较少，因此低分辨率下使用合成图像进行增强的机会更大。高分辨率下性能提升到1M合成图像后缓慢下降；这可能表明模型在高分辨率下存在更大的偏差，或者需要使用合成数据进行更复杂的训练方法。这些问题仍然是正在进行的研究的主题。
